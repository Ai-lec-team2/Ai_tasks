{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "840752ad-b21a-443f-ba27-cfe7eb6a233d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "which: no ccache in (/home/sam/Documents/GitHub/Ai_tasks/.venv/bin:/home/linuxbrew/.linuxbrew/bin:/home/linuxbrew/.linuxbrew/sbin:/home/sam/.pyenv/plugins/pyenv-virtualenv/shims:/home/sam/.pyenv/shims:/home/sam/.pyenv/bin:/home/linuxbrew/.linuxbrew/bin:/home/linuxbrew/.linuxbrew/sbin:/home/sam/.nvm/versions/node/v22.14.0/bin:/home/sam/.local/bin:/home/sam/bin:/usr/local/bin:/usr/local/sbin:/usr/bin:/usr/sbin)\n",
      "/home/sam/Documents/GitHub/Ai_tasks/.venv/lib64/python3.13/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/05/19 10:12:48] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, use_gcu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/home/sam/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/home/sam/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/home/sam/Documents/GitHub/Ai_tasks/.venv/lib64/python3.13/site-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/home/sam/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, onnx_providers=False, onnx_sess_options=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2025/05/19 10:12:49] ppocr DEBUG: dt_boxes num : 5, elapsed : 0.22313332557678223\n",
      "[2025/05/19 10:12:49] ppocr DEBUG: cls num  : 5, elapsed : 0.028200864791870117\n",
      "[2025/05/19 10:12:50] ppocr DEBUG: rec_res num  : 5, elapsed : 0.8867533206939697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Step 1: Load image and initialize OCR\n",
    "img_path = \"image_1007.jpg\"\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "result = ocr.ocr(img_path, cls=True)\n",
    "\n",
    "# Step 2: Read image with OpenCV\n",
    "image = cv2.imread(img_path)\n",
    "mask = np.zeros(image.shape[:2], dtype=np.uint8)  # start with a black mask\n",
    "\n",
    "# Step 3: Draw white-filled polygons on mask for all detected text boxes\n",
    "for line in result[0]:\n",
    "    points = np.array(line[0]).astype(np.int32)\n",
    "    cv2.fillPoly(mask, [points], 255)  # white area marks text\n",
    "\n",
    "# Optional: visualize where the text is\n",
    "# cv2.imwrite(\"text_mask.jpg\", mask)\n",
    "\n",
    "# Step 4: Inpaint (remove text)\n",
    "inpainted = cv2.inpaint(image, mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)\n",
    "cv2.imwrite(\"cleaned_image.jpg\", inpainted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "717b4e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load key from .env\n",
    "key = open(\".env\").readline() \n",
    "key = key.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b98e764d-5ac7-46c3-aedf-96c29ca2504e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/05/19 16:23:27] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, use_gcu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/home/sam/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/home/sam/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/home/sam/Documents/GitHub/Ai_tasks/.venv/lib64/python3.13/site-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/home/sam/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, onnx_providers=False, onnx_sess_options=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2025/05/19 16:23:28] ppocr DEBUG: dt_boxes num : 5, elapsed : 0.12727069854736328\n",
      "[2025/05/19 16:23:28] ppocr DEBUG: cls num  : 5, elapsed : 0.01307535171508789\n",
      "[2025/05/19 16:23:29] ppocr DEBUG: rec_res num  : 5, elapsed : 0.9086391925811768\n",
      "🧠 Detected: HAVEYOUEVERBEENREVSNG YOUR FINALS.WORRYING ABOUTWHETHERYOUWLLPASSORNOT ANDTHEN YOUREACHAPOINTWHEREYOUSAY STARECAT.COM FUCK.THS. SHT\n",
      "🧼 Cleaned Caption: HAVE YOU EVER BEEN STUDYING FOR YOUR FINALS, WORRYING ABOUT WHETHER YOU WILL PASS OR NOT, AND THEN YOU REACH A POINT WHERE YOU SAY, \"STARECAT.COM FORGET THIS STUFF!\"\n",
      "Removing: HAVEYOUEVERBEENREVSNG YOUR FINALS.WORRYING\n",
      "Removing: ABOUTWHETHERYOUWLLPASSORNOT\n",
      "Removing: ANDTHEN YOUREACHAPOINTWHEREYOUSAY\n",
      "Removing: STARECAT.COM\n",
      "Removing: FUCK.THS. SHT\n",
      "✅ Inpainted image saved.\n",
      "📄 HTML saved as meme_output.html\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from paddleocr import PaddleOCR\n",
    "\n",
    "# === Set up OpenAI client ===\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=key)  # Replace with your key\n",
    "\n",
    "# === Load image ===\n",
    "img_path = \"image_1007.jpg\"\n",
    "image = cv2.imread(img_path)\n",
    "\n",
    "# === Run OCR ===\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "result = ocr.ocr(img_path, cls=True)\n",
    "\n",
    "# === Extract text for GPT ===\n",
    "detected_texts = [line[1][0] for line in result[0]]\n",
    "full_text = \" \".join(detected_texts)\n",
    "print(\"🧠 Detected:\", full_text)\n",
    "\n",
    "# === Send to GPT-4o ===\n",
    "comparison_prompt = f\"\"\"\n",
    "You are an assistant that rewrites meme captions to be suitable for children under 13 years old.\n",
    "Keep the message fun but remove any inappropriate or mature language.\n",
    "But please keep the original meaning and context of the meme.\n",
    "\n",
    "Original: {full_text}\n",
    "\n",
    "Kid-Friendly version:\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[{\"role\": \"user\", \"content\": comparison_prompt}],\n",
    "    max_tokens=150,\n",
    "    temperature=0.8\n",
    ")\n",
    "cleaned_caption = response.choices[0].message.content\n",
    "if cleaned_caption != None:\n",
    "    cleaned_caption = cleaned_caption.strip()\n",
    "print(\"🧼 Cleaned Caption:\", cleaned_caption)\n",
    "\n",
    "# === Create mask from text bounding boxes ===\n",
    "mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "for line in result[0]:\n",
    "    print(\"Removing:\", line[1][0])\n",
    "    points = np.array(line[0]).astype(np.int32)\n",
    "    points = points.reshape((-1, 1, 2))  # Ensure correct shape for fillPoly\n",
    "    cv2.fillPoly(mask, [points], 255)\n",
    "\n",
    "# === Inpaint ===\n",
    "inpainted = cv2.inpaint(image, mask, 3, cv2.INPAINT_TELEA)\n",
    "cv2.imwrite(\"cleaned_image.jpg\", inpainted)\n",
    "print(\"✅ Inpainted image saved.\")\n",
    "\n",
    "# === Generate HTML output ===\n",
    "html = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head><meta charset=\"UTF-8\"><title>Meme for Kids</title></head>\n",
    "<body style=\"text-align:center; font-family:sans-serif;\">\n",
    "  <h2>Cleaned Meme</h2>\n",
    "  <img src=\"cleaned_image.jpg\" width=\"500\"/><br/><br/>\n",
    "  <p><strong>Caption:</strong> {cleaned_caption}</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "with open(\"meme_output.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html)\n",
    "\n",
    "print(\"📄 HTML saved as meme_output.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3024c8eb-9c29-4692-8420-1d2b8e38f72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ HTML with embedded image saved.\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "# Convert inpainted image to PIL and then to base64\n",
    "inpainted_rgb = cv2.cvtColor(inpainted, cv2.COLOR_BGR2RGB)\n",
    "pil_img = Image.fromarray(inpainted_rgb)\n",
    "buffered = io.BytesIO()\n",
    "pil_img.save(buffered, format=\"JPEG\")\n",
    "img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "# Use in HTML\n",
    "html = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head><meta charset=\"UTF-8\"><title>Meme for Kids</title></head>\n",
    "<body style=\"text-align:center; font-family:sans-serif;\">\n",
    "  <h2>Cleaned Meme</h2>\n",
    "  <img src=\"data:image/jpeg;base64,{img_str}\" width=\"500\"/><br/><br/>\n",
    "  <p><strong>Caption:</strong> {cleaned_caption}</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "with open(\"meme_output.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html)\n",
    "\n",
    "print(\"✅ HTML with embedded image saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c550ca17",
   "metadata": {},
   "source": [
    "Below is the latest version it takes the images detects the text and than asks gpt partially for detection of inappropriateness and than retruns safe or what to change. if there is change needed we put a black box where the text is at and than rewrite the clean version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e074d038-0256-47aa-9a40-3a3f8c568968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/05/19 16:51:05] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, use_gcu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/home/sam/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/home/sam/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/home/sam/Documents/GitHub/Ai_tasks/.venv/lib64/python3.13/site-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/home/sam/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, onnx_providers=False, onnx_sess_options=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/05/19 16:51:06] ppocr DEBUG: dt_boxes num : 10, elapsed : 0.06732916831970215\n",
      "[2025/05/19 16:51:06] ppocr DEBUG: cls num  : 10, elapsed : 0.03676247596740723\n",
      "[2025/05/19 16:51:07] ppocr DEBUG: rec_res num  : 10, elapsed : 0.7555530071258545\n",
      "🧠 Original: INAMEDMYHARD → GPT Reply: SAFE\n",
      "🧠 Original: DRIVE \"DAT ASS\" → GPT Reply: DRIVE \"THAT CAR\"\n",
      "Capitalized: DRIVE THAT CAR\n",
      "🧠 Original: SOTHATONCEAMONTH MYCOMPUTER WILL → GPT Reply: SAFE\n",
      "🧠 Original: ASK ME IF I WANT TO BACK DAT ASS UP. → GPT Reply: ASK ME IF I WANT TO BACK THAT UP.\n",
      "Capitalized: ASK ME IF I WANT TO BACK THAT UP\n",
      "✅ Saved: partially_cleaned_image2.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from paddleocr import PaddleOCR\n",
    "from openai import OpenAI\n",
    "\n",
    "# === Setup OpenAI client ===\n",
    "client = OpenAI(api_key=key)  # ← 🔑 Replace with your actual key\n",
    "\n",
    "# === Load image ===\n",
    "img_path = \"image_1057.jpg\"\n",
    "image = cv2.imread(img_path)\n",
    "\n",
    "# === Run OCR ===\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "result = ocr.ocr(img_path, cls=True)\n",
    "\n",
    "def black_box_and_replace(image, box, cleaned_text, font_scale=1.0, thickness=2):\n",
    "    pts = np.array(box).astype(np.int32)\n",
    "    x1 = min([p[0] for p in pts])\n",
    "    y1 = min([p[1] for p in pts])\n",
    "    x2 = max([p[0] for p in pts])\n",
    "    y2 = max([p[1] for p in pts])\n",
    "\n",
    "    # Draw solid black rectangle\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 0, 0), thickness=-1)\n",
    "\n",
    "    # Calculate font size to fit the box\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    text_size, _ = cv2.getTextSize(cleaned_text, font, font_scale, thickness)\n",
    "    text_width, text_height = text_size\n",
    "\n",
    "    # Adjust font size to fit the box\n",
    "    max_width = x2 - x1 - 10\n",
    "    while text_width > max_width and font_scale > 0.3:\n",
    "        font_scale -= 0.05\n",
    "        text_size, _ = cv2.getTextSize(cleaned_text, font, font_scale, thickness)\n",
    "        text_width, text_height = text_size\n",
    "\n",
    "    # Center text in box\n",
    "    text_x = x1 + (x2 - x1 - text_width) // 2\n",
    "    text_y = y1 + (y2 - y1 + text_height) // 2\n",
    "\n",
    "    # Draw white text on black box\n",
    "    cv2.putText(image, cleaned_text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)\n",
    "\n",
    "    return image\n",
    "\n",
    "# === Process Each OCR Text Box ===\n",
    "for line in result[0]:\n",
    "    box = line[0]\n",
    "    text = line[1][0].strip()\n",
    "\n",
    "    if len(text) < 2:\n",
    "        continue  # skip short garbage\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a content moderation assistant for meme captions.\n",
    "\n",
    "Your job is to check if the input text is inappropriate for children under 13.\n",
    "\n",
    "If the input **contains inappropriate language**, rewrite it into a **natural, clean, and child-appropriate version** that:\n",
    "- Preserves the original intent or emotion (e.g., frustration, surprise, humor)\n",
    "- Uses **real and understandable words**\n",
    "- Avoids made-up substitutes or censored spellings (e.g., no asterisks or partial words)\n",
    "- Uses normal sentence structure (not dot-separated words)\n",
    "\n",
    "Keep the new version **similar in length** to the original so it fits visually in the image.\n",
    "Also, as the OCR detection can be unstable, I provide you with just one OCR'red line, as well as the complete ocr detectio.\n",
    "This can enable you to use the complete context of the meme for your decision.\n",
    "\n",
    "The full OCR context: {result[0]} <-- the full context is just for meaningful meme context, this does not influence your answer in terms of if its SAFE or not.\n",
    "\n",
    "Just the current line: {text} <-- if the current does not contain any impolite or inappropriate words (also slang), just reply with SAFE.\n",
    "\n",
    "Only reply either with \"SAFE\" or the child-friendly version of the text. Do not include your reasoning or any other context in your answer.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.3,\n",
    "            max_tokens=60\n",
    "        )\n",
    "        reply = response.choices[0].message.content\n",
    "        if reply != None:\n",
    "            reply = reply.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ GPT failed on '{text}': {e}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"🧠 Original: {text} → GPT Reply: {reply}\")\n",
    "\n",
    "    # === Filter safe results ===\n",
    "    if reply != None and reply.upper() != \"SAFE\":\n",
    "        cleaned_text = reply.replace('\"', '').replace(\"...\", \" \").replace(\"..\", \" \").replace(\".\", \" \").strip()\n",
    "        # Check if the original text was in only uppercase\n",
    "        cleaned_text = cleaned_text.capitalize()\n",
    "        if text == text.upper():\n",
    "            cleaned_text = cleaned_text.upper()\n",
    "        print(\"Capitalized:\", cleaned_text)\n",
    "        image = black_box_and_replace(image, box, cleaned_text)\n",
    "\n",
    "# === Save Final Output ===\n",
    "cv2.imwrite(\"partially_cleaned_image2.jpg\", image)\n",
    "print(\"✅ Saved: partially_cleaned_image2.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7815a1-3398-4d4b-a2c5-be380afb1bef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
